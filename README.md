# Система детекции объектов на видео для магазина

Данный проект представляет собой систему для обнаружения объектов на видео в режиме реального времени. Система использует модель глубокого обучения SSDLite MobileNetV3 Large для детекции таких объектов, как паллеты, купола и люди

## Постановка задачи

Необходимо было разработать систему для магазина, которая фиксирует следующие события:
- Появление человека в кадре (с отслеживанием)
- Появление паллета в кадре (пустого или с продукцией)
- Факт накрытия паллета куполом

Система должна была работать на устройствах с ограниченными ресурсами (например, Raspberry Pi) и формировать отчет в виде таблицы (Время события, Тип события, Фото)

## Реализованный функционал

- **Детекция объектов**: Система способна обнаруживать следующие классы объектов:
    - `pallet` (паллет)
    - `dome` (купол)
    - `Human` (человек)
- **Модель**: Используется предварительно обученная модель SSDLite MobileNetV3 Large, адаптированная для кастомного набора классов. Веса модели (`ssdlite_mobilenetv3_custom_final.pth`) находятся в директории `models/`
- **Обработка видео**: Система обрабатывает видеофайлы, отображает рамки вокруг обнаруженных объектов и их классы с степенью уверенностью
- **Логирование событий**: Информация об обнаруженных объектах (временная метка, тип события, класс объекта, уверенность, координаты рамки) выводится в консоль
- **Сохранение результата**: Есть возможность сохранить обработанное видео с наложенной информацией о детекциях
- **Оценка производительности**: Скрипт детекции выводит среднее количество кадров в секунду (FPS), обработанных системой

![Демонстрация работы проекта](assets/2025-06-05-09-18-22.gif)

## Технологии

- Python 3.x
- PyTorch
- Torchvision
- OpenCV-Python
- NumPy
- Pillow

## Структура проекта

```
VideoDetectionStoreSystem_Repo/
├── data/                 #Директория для хранения данных
│   ├── images/           #Неразмеченные данные
│   ├── processed_data/   #Обработанные данные
│   ├── video/            #Исходные видеофайлы
|   └── assets/           #Гиф анимация работы модели
├── models/               #Обученные модели
│   └── ssdlite_mobilenetv3_custom_final.pth
├── src/                  #Исходный код
│   ├── dataset.py        #Скрипт для работы с датасетом
│   ├── detect_on_video.py #Основной скрипт для детекции на видео
│   ├── GenerateImages.py #Скрипт для генерации изображений из видео
│   ├── model.py          #Определение архитектуры модели
│   └── train.py          #Скрипт для обучения модели
└── requirements.txt      #Файл с зависимостями
```

## Установка

1.  **Клонируйте репозиторий:**
    ```bash
    git clone <URL_вашего_репозитория>
    cd VideoDetectionStoreSystem_Repo
    ```

2.  **Создайте и активируйте виртуальное окружение (рекомендуется):**
    ```bash
    python -m venv venv
    # Для Windows
    venv\Scripts\activate
    # Для macOS/Linux
    source venv/bin/activate
    ```

3.  **Установите зависимости:**
    ```bash
    pip install -r requirements.txt
    ```
    *Примечание: В файле `requirements.txt` перечислены основные зависимости. Возможно, потребуется подобрать конкретные версии, совместимые с вашим окружением (`torch`, `torchvision` особенно чувствительны к версиям CUDA, если используется GPU).*

4.  **Модель**: Файл с весами модели `ssdlite_mobilenetv3_custom_final.pth` уже должен находиться в директории `models/`

## Использование

Для запуска детекции на видео используйте скрипт `src/detect_on_video.py`

```bash
python src/detect_on_video.py --model_path models/ssdlite_mobilenetv3_custom_final.pth --video_path data/video/your_video_file.mp4 --threshold 0.5
```

**Аргументы командной строки:**
-   `--model_path`: Путь к файлу с весами модели (обязательный)
-   `--video_path`: Путь к видеофайлу для обработки (обязательный)
-   `--output_video_path` (опционально): Путь для сохранения обработанного видео. Если не указан, видео не сохраняется
    Пример: `--output_video_path data/video/output_detected_video.mp4`
-   `--threshold` (опционально): Порог уверенности для отображения детекций. Значение от 0.0 до 1.0. По умолчанию `0.5`

*Пример захардкоженных путей в `detect_on_video.py` был предназначен для разработки и может потребовать изменения для вашего окружения.*

## Что не реализовано (из исходной постановки задачи)

-   **Разделение паллет**: Модель не различает "деревянный" и "пластиковый" паллеты, используется общий класс `pallet`
-   **Событие "паллет накрыли куполом"**: Специализированная логика для детекции этого сложного события отсутствует. Текущая система детектирует паллеты и купола по отдельности, но уверена в наличии купола, когда он развёрнут (большого размера), что технически можно считать "накрытием"
-   **Отслеживание (Tracking) объектов**: Система обнаруживает объекты на каждом кадре независимо. Явный трекинг (присвоение ID объекту и его отслеживание между кадрами) не реализован
-   **Формирование отчета**: Вывод результатов в виде таблицы "Время события, Тип события, Фото" и сохранение отдельных фотографий событий не реализованы. Логи выводятся в консоль (Структурно в виде таблицы, что технически можно считать выполненым)


## Возможные доработки и улучшения

-   Реализовать логику для определения события "паллет накрыли куполом", анализируя взаимное расположение и временную последовательность появления/исчезновения объектов "паллет" и "купол"
-   Провести более детальную оценку производительности и точности на целевых устройствах (Raspberry Pi, Orange Pi) и при необходимости дополнительно оптимизировать модель или конвейер обработки
-   Подготовить детальное обоснование выбора архитектуры и фреймворка
-   Дообучить модель на втором видео